{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/infodev1/infoderm/Projects/Naresh/scripts/misc/TCGA_BRCA_PAM50\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-19 19:32:40.424208: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "# for loading/processing the images  \n",
    "from tensorflow.keras.preprocessing.image import load_img \n",
    "from tensorflow.keras.preprocessing.image import img_to_array \n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input \n",
    "\n",
    "# models \n",
    "from tensorflow.keras.applications.vgg16 import VGG16 \n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# clustering and dimension reduction\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# for everything else\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import pickle# for loading/processing the \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import glob\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import matplotlib.pylab as plt\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "import glob\n",
    "#from preprocess import Preprocess, format_example, format_example_tf, update_status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogluon.core as ag\n",
    "#from autogluon.vision import ImagePredictor, ImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flowers_full = glob.glob(\"/research/bsi/projects/breast/s301449.LARdl/processing/MOLI/MOLI_code/Keras/xiaojia_code/methyl_data/AD_vs_CN.images1/*/*/*png\")\n",
    "seed=\"1010\"\n",
    "flowers_full = glob.glob(\"/infodev1/infoderm/Projects/Naresh/scripts/misc/TCGA_BRCA_PAM50/images/images.\"+seed+\"/*/*/*png\")\n",
    "flowers = {}\n",
    "for i in flowers_full:\n",
    "    flowers[os.path.basename(i)] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(flowers_full),flowers_full[0],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['TCGA.B6.A0RT.01A.png',\n",
       "  'TCGA.BH.A0AV.01A.png',\n",
       "  'TCGA.LL.A6FR.01A.png',\n",
       "  'TCGA.AO.A12F.01A.png'],\n",
       " '/infodev1/infoderm/Projects/Naresh/scripts/misc/TCGA_BRCA_PAM50/images/images.1010/test/2/TCGA.B6.A0RT.01A.png')"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = list(flowers.keys())\n",
    "keys[1:5],flowers[keys[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate={}\n",
    "lbl={}\n",
    "for i in keys:\n",
    "    lbl[i]=os.path.basename(os.path.dirname(flowers[i]))\n",
    "    cate[i]=os.path.basename(os.path.dirname(os.path.dirname(flowers[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = load_img(flowers[keys[10]], target_size=(224,224))\n",
    "#img.save(\"temp.png\")\n",
    "#img = np.array(img) \n",
    "#plt.figure(num=None, figsize=(8, 6), dpi=80)\n",
    "#plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cv.imread(flowers[keys[10]], cv.IMREAD_UNCHANGED)#cv2.IMREAD_COLOR)IMREAD_UNCHANGED\n",
    "#img = cv.resize(img, (224,224), interpolation = cv.INTER_AREA)\n",
    "#cv.imwrite(\"cv2_tmp.png\", img)\n",
    "#plt.figure(num=None, figsize=(8, 6), dpi=80)\n",
    "#plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "#image = Image.open(flowers[keys[10]])\n",
    "#image = image.resize((224,224),Image.ANTIALIAS)\n",
    "#image.save(fp=\"newimage.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.color import rgb2hsv, rgb2gray, rgb2yuv\n",
    "from skimage import color, exposure, transform\n",
    "from skimage.exposure import equalize_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16()\n",
    "model = Model(inputs = model.inputs, outputs = model.layers[-2].output)\n",
    "\n",
    "def extract_features(file, model):\n",
    "    # load the image as a 224x224 array\n",
    "    #img = load_img(file, target_size=(224,224))\n",
    "    # convert from 'PIL.Image.Image' to numpy array\n",
    "    #img = np.array(img)\n",
    "    img = cv.imread(file, cv.IMREAD_UNCHANGED)#cv2.IMREAD_COLOR)IMREAD_UNCHANGED\n",
    "    img = cv.resize(img, (224,224), interpolation = cv.INTER_CUBIC)\n",
    "    # reshape the data for the model reshape(num_of_samples, dim 1, dim 2, channels)\n",
    "    reshaped_img = img.reshape(1,224,224,3) \n",
    "    # prepare image for model\n",
    "    imgx = preprocess_input(reshaped_img)\n",
    "    # get the feature vector\n",
    "    features = model.predict(imgx, use_multiprocessing=True)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "#p = \"/research/bsi/projects/breast/s301449.LARdl/processing/MOLI/MOLI_code/Keras/xiaojia_code/output/all_vec/allvec\"\n",
    "p = \"/infodev1/infoderm/Projects/Naresh/scripts/Kiosk/runs/cats_dogs_feavec\"\n",
    "# lop through each image in the dataset\n",
    "for flower in keys:\n",
    "    # try to extract the features and update the dictionary\n",
    "    #try:\n",
    "    #print(flower)\n",
    "    feat = extract_features(flowers[flower],model)\n",
    "    data[flower] = feat\n",
    "    # if something fails, save the extracted features as a pickle file (optional)\n",
    "    #except:\n",
    "    #    with open(p,'wb') as file:\n",
    "    #        pickle.dump(data,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "828"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4096)"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[keys[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/infodev1/infoderm/Projects/Naresh/scripts/misc/TCGA_BRCA_PAM50/images/images.1010/test/2/TCGA.LL.A8F5.01A.png'"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flowers[keys[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of the filenames\n",
    "#filenames = np.array(list(data.keys()))\n",
    "filenames = np.array([i for i in keys])\n",
    "# get a list of just the features\n",
    "#feat = np.array(list(data.values()))\n",
    "feat = np.array([data[i] for i in keys])\n",
    "# reshape so that there are 210 samples of 4096 vectors\n",
    "feat = feat.reshape(-1,4096)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((828, 4096),\n",
       " array(['TCGA.LL.A8F5.01A.png', 'TCGA.B6.A0RT.01A.png',\n",
       "        'TCGA.BH.A0AV.01A.png', 'TCGA.LL.A6FR.01A.png',\n",
       "        'TCGA.AO.A12F.01A.png'], dtype='<U20'),\n",
       " ['TCGA.B6.A0RT.01A.png',\n",
       "  'TCGA.BH.A0AV.01A.png',\n",
       "  'TCGA.LL.A6FR.01A.png',\n",
       "  'TCGA.AO.A12F.01A.png'],\n",
       " 828)"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat.shape,filenames[:5],keys[1:5],len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_lbl = [lbl[i] for i in keys]\n",
    "list_cate = [cate[i] for i in keys]\n",
    "list_lbl_cate = [lbl[i]+'_'+cate[i] for i in keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'2_test': 22,\n",
       "         '3_test': 10,\n",
       "         '0_test': 64,\n",
       "         '1_test': 25,\n",
       "         '2_train': 109,\n",
       "         '3_train': 53,\n",
       "         '0_train': 302,\n",
       "         '1_train': 122,\n",
       "         '2_val': 22,\n",
       "         '3_val': 10,\n",
       "         '0_val': 64,\n",
       "         '1_val': 25})"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "#list_lbl[0:5],list_cate[0:5],list_lbl_cate[0:5]\n",
    "Counter(list_lbl_cate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_train = [list_lbl[i] for i in range(0,len(list_cate),1) if list_cate[i] == \"train\" ]\n",
    "cate_val = [list_lbl[i] for i in range(0,len(list_cate),1) if list_cate[i] == \"val\" ]\n",
    "cate_test = [list_lbl[i] for i in range(0,len(list_cate),1) if list_cate[i] == \"test\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ind = [i for i in range(0,len(list_cate),1) if list_cate[i] == \"train\" ]\n",
    "val_ind = [i for i in range(0,len(list_cate),1) if list_cate[i] == \"val\" ]\n",
    "test_ind = [i for i in range(0,len(list_cate),1) if list_cate[i] == \"test\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(586, 121, 121)"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ind),len(val_ind),len(test_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_np = feat[val_ind,]\n",
    "filenm_val = [ filenames[i] for i in val_ind]\n",
    "test_np = feat[test_ind,]\n",
    "filenm_test = [ filenames[i] for i in test_ind]\n",
    "train_np = feat[train_ind,]\n",
    "filenm_train = [ filenames[i] for i in train_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l_lst\n",
    "#len(cate_0),len(cate_1)\n",
    "#val_np.shape,test_np.shape,train_np.shape,filenames[test_ind[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50, random_state=22)\n",
    "pca.fit(train_np)\n",
    "x = pca.transform(train_np)\n",
    "x_val = pca.transform(val_np)\n",
    "x_test = pca.transform(test_np)\n",
    "\n",
    "#range_n_clusters = [2,3,4,5,6,7,8,9]\n",
    "#silhouette_avg = []\n",
    "#for num_clusters in range_n_clusters:\n",
    "# \n",
    "# # initialise kmeans\n",
    "# kmeans = KMeans(n_clusters=num_clusters)\n",
    "# kmeans.fit(x)\n",
    "# cluster_labels = kmeans.labels_\n",
    "# silhouette_avg.append(silhouette_score(x, cluster_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filenm_train[0:5],set(cate_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ori_train = [ i for i in cate_train ]\n",
    "y_ori_val = [ i for i in cate_val ]\n",
    "y_ori_test = [ i for i in cate_test ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(586, 121, 121, (586, 50), (121, 50), (121, 50))"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_ori_train),len(y_ori_val),len(y_ori_test),x.shape,x_val.shape,x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[59  5  0  0]\n",
      " [17  6  2  0]\n",
      " [ 4  2 15  1]\n",
      " [ 8  0  0  2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "classifier.fit(x, y_ori_train)\n",
    "y_pred = classifier.predict(x_val)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_ori_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.92      0.78        64\n",
      "           1       0.46      0.24      0.32        25\n",
      "           2       0.88      0.68      0.77        22\n",
      "           3       0.67      0.20      0.31        10\n",
      "\n",
      "    accuracy                           0.68       121\n",
      "   macro avg       0.67      0.51      0.54       121\n",
      "weighted avg       0.67      0.68      0.64       121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_ori_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[57  5  0  2]\n",
      " [17  5  3  0]\n",
      " [ 7  0 15  0]\n",
      " [ 8  0  1  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.89      0.75        64\n",
      "           1       0.50      0.20      0.29        25\n",
      "           2       0.79      0.68      0.73        22\n",
      "           3       0.33      0.10      0.15        10\n",
      "\n",
      "    accuracy                           0.64       121\n",
      "   macro avg       0.57      0.47      0.48       121\n",
      "weighted avg       0.61      0.64      0.60       121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(x_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_ori_test, y_pred))\n",
    "print(classification_report(y_ori_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.93      0.80       302\n",
      "           1       0.61      0.38      0.46       122\n",
      "           2       0.91      0.77      0.84       109\n",
      "           3       0.79      0.28      0.42        53\n",
      "\n",
      "    accuracy                           0.73       586\n",
      "   macro avg       0.75      0.59      0.63       586\n",
      "weighted avg       0.73      0.73      0.70       586\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = classifier.predict(x)\n",
    "print(classification_report(y_ori_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fobj =open('out.xls','wt')\n",
    "#for i in  range(0,len(filenm_val),1):\n",
    "#    fobj.write(flowers[filenm_val[i]]+\" \"+y_ori_val[i]+\" \"+y_pred[i]+\"\\n\")\n",
    "#for i in  range(0,len(filenm_train),1):\n",
    "#    fobj.write(flowers[filenm_train[i]]+\" \"+y_ori_train[i]+\" \"+y_pred_train[i]+\"\\n\")\n",
    "#fobj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogluon as ag\n",
    "from autogluon.tabular import TabularPredictor as task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((586, 50), (121, 50), (121, 50))"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,x_val.shape,x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames=[ \"feature\"+str(i) for i in range(0,50,1)]\n",
    "len(colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(x, columns = colnames)\n",
    "test_df = pd.DataFrame(x_test, columns = colnames)\n",
    "val_df = pd.DataFrame(x_val, columns = colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.shape,test_df.shape,val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['label']=y_ori_train\n",
    "test_df['label']=y_ori_test\n",
    "val_df['label']=y_ori_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/infodev1/infoderm/Projects/Naresh/scripts/Kiosk/runs/tmp_ag\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/infodev1/infoderm/Projects/Naresh/scripts/Kiosk/runs/tmp_ag/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.9.7\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Tue Jun 20 11:48:01 UTC 2023\n",
      "Train Data Rows:    586\n",
      "Train Data Columns: 50\n",
      "Tuning Data Rows:    121\n",
      "Tuning Data Columns: 50\n",
      "Label Column: label\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\t4 unique label values:  ['2', '3', '0', '1']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    391328.84 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.14 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 50 | ['feature0', 'feature1', 'feature2', 'feature3', 'feature4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 50 | ['feature0', 'feature1', 'feature2', 'feature3', 'feature4', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t50 features in original data used to generate 50 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.14 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'balanced_accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.5109\t = Validation score   (balanced_accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.5395\t = Validation score   (balanced_accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "Metric balanced_accuracy is not supported by this model - using log_loss instead\n",
      "No improvement since epoch 7: early stopping\n",
      "\t0.5891\t = Validation score   (balanced_accuracy)\n",
      "\t0.57s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.5736\t = Validation score   (balanced_accuracy)\n",
      "\t1.41s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.59\t = Validation score   (balanced_accuracy)\n",
      "\t1.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.4405\t = Validation score   (balanced_accuracy)\n",
      "\t0.51s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.4152\t = Validation score   (balanced_accuracy)\n",
      "\t0.57s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.6142\t = Validation score   (balanced_accuracy)\n",
      "\t4.68s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.3636\t = Validation score   (balanced_accuracy)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.3636\t = Validation score   (balanced_accuracy)\n",
      "\t0.52s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.5784\t = Validation score   (balanced_accuracy)\n",
      "\t1.3s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.6842\t = Validation score   (balanced_accuracy)\n",
      "\t2.76s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.5747\t = Validation score   (balanced_accuracy)\n",
      "\t3.79s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.6998\t = Validation score   (balanced_accuracy)\n",
      "\t0.55s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 19.38s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/infodev1/infoderm/Projects/Naresh/scripts/Kiosk/runs/tmp_ag/\")\n"
     ]
    }
   ],
   "source": [
    "save_path=\"/infodev1/infoderm/Projects/Naresh/scripts/Kiosk/runs/tmp_ag\"\n",
    "predictor = task(label='label', path=save_path,eval_metric = \"balanced_accuracy\").fit(train_data=train_df,tuning_data=val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictor = task.fit(train_data=train_df, tuning_data=val_df, label='label',eval_metric = \"accuracy\")\n",
    "import autogluon.core as ag\n",
    "\n",
    "#gbm_options = {  # specifies non-default hyperparameter values for lightGBM gradient boosted trees\n",
    "#    'num_boost_round': 100,  # number of boosting rounds (controls training time of GBM models)\n",
    "#    'num_leaves': ag.space.Int(lower=3, upper=50, default=36),  # number of leaves in trees (integer hyperparameter)\n",
    "#}\n",
    "\n",
    "#hyperparameters = {  # hyperparameters of each model type\n",
    "#                   'GBM': gbm_options,\n",
    "#                    # NOTE: comment this line out if you get errors on Mac OSX\n",
    "#                  }  # When these keys are missing from hyperparameters dict, no models of that type are trained\n",
    "\n",
    "#time_limit = 2*60  # train various models for ~2 min\n",
    "#num_trials = 5  # try at most 5 different hyperparameter configurations for each type of model\n",
    "#search_strategy = 'auto'  # to tune hyperparameters using random search routine with a local scheduler\n",
    "\n",
    "#hyperparameter_tune_kwargs = {  # HPO is not performed unless hyperparameter_tune_kwargs is specified\n",
    "#    'num_trials': num_trials,\n",
    "#    'scheduler' : 'local',\n",
    "#    'searcher': search_strategy,\n",
    "#}\n",
    "\n",
    "#save_path=\"/research/bsi/projects/breast/s301449.LARdl/processing/MOLI/MOLI_code/Keras/xiaojia_code/Kevin_Pac/ag_model\"\n",
    "#predictor = task(label='label', path=save_path,eval_metric = \"accuracy\").fit(train_data=train_df,tuning_data=val_df,  time_limit=time_limit,\n",
    "#    hyperparameters=hyperparameters, hyperparameter_tune_kwargs=hyperparameter_tune_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: balanced_accuracy on test data: 0.6235653409090909\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"balanced_accuracy\": 0.6235653409090909,\n",
      "    \"accuracy\": 0.743801652892562,\n",
      "    \"mcc\": 0.5853273109717716\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "performance = predictor.evaluate(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performance = predictor.evaluate(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data_nolab = test_df.drop(columns=['label'])\n",
    "y_pred = predictor.predict(test_data_nolab)\n",
    "#print(\"Predictions:  \\n\", y_pred)\n",
    "#perf = predictor.evaluate_predictions(y_true=y_test, y_pred=y_pred, auxiliary_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import glob\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn import metrics\n",
    "import re\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "def report(fish_list, result_list,prob, name):\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(fish_list, result_list).ravel()\n",
    "    tn=int(tn)\n",
    "    fp=int(fp)\n",
    "    fn=int(fn)\n",
    "    tp=int(tp)\n",
    "    #sys.exit(0)    \n",
    "    sensitivity=round(tp/(tp+fn),2)\n",
    "    #print(sensitivity)\n",
    "    #sys.exit(0)    \n",
    "    specificity=round(tn/(tn+fp),2)\n",
    "    accuracy=round((tp + tn)/(tn + fp + fn + tp),2)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(fish_list, result_list, pos_label=1)\n",
    "    #auc = round(metrics.auc(fpr, tpr),2)\n",
    "    #print(name , \"TN:\",tn, \"FP:\",fp, \"FN:\",fn, \"TP:\",tp, \"Sensitivity:\",sensitivity, \"Specificity:\",specificity, \"AUC:\",auc,\"Accuracy:\",accuracy)\n",
    "    #print(name,tn,fp,fn,tp,sensitivity,specificity,auc,accuracy)\n",
    "    target_names = ['class 0', 'class 1']\n",
    "    cr = classification_report(fish_list, result_list, target_names=target_names)\n",
    "    cr = re.sub('\\n+', '\\n', cr)\n",
    "    cr = re.sub(' +', ' ', cr)\n",
    "    cr = re.sub('\\n ', '\\n', cr)\n",
    "    cr_a = cr.split(\"\\n\")\n",
    "    pres = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    for i in range(1,3,1):\n",
    "        cr_a_t = cr_a[i].split(\" \")\n",
    "        pres.append(cr_a_t[len(cr_a_t)-4])\n",
    "        recall.append(cr_a_t[len(cr_a_t)-3])\n",
    "        f1.append(cr_a_t[len(cr_a_t)-2])\n",
    "    presc = ' '.join(pres)\n",
    "    recallc = ' '.join(recall)\n",
    "    f1c = ' '.join(recall)\n",
    "    weighted_acc=cr_a[5].split(\" \")[2]\n",
    "    \n",
    "    #test_precision, test_recall, _ = precision_recall_curve(fish_list, prob)\n",
    "    #auc1 =  auc(test_recall, test_precision)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(fish_list, prob)\n",
    "    auc1 = round(metrics.auc(fpr, tpr),2)\n",
    "    print(name,tn,fp,fn,tp,sensitivity,specificity,auc1,accuracy,presc,recallc,f1c,weighted_acc)\n",
    "    #print(cr_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictor.leaderboard(test_df,silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(\"name\",\"tn\",\"fp\",\"fn\",\"tp\",\"sensitivity\",\"specificity\",\"auc\",\"accuracy\",\"presc1\",\"presc2\",\"recallc1\",\"recallc2\",\"f1_score_c1\",\"f1_score_c2\",\"weighted_acc\")  \n",
    "myfile = open(seed+\"_all.txt\", mode='wt')\n",
    "y_pred = predictor.predict(test_df, model='NeuralNetTorch')\n",
    "y_prob = predictor.predict_proba(test_df)\n",
    "y_pred=[int(i) for i in list(y_pred)]\n",
    "y_true=[int(i) for i in list(test_df[\"label\"])]\n",
    "#report(y_true, y_pred,list(y_prob.iloc[:,1]), \"test\")\n",
    "for i in range(0,len(y_true)):\n",
    "    inx_mx=np.argmax(y_prob.iloc[i,:])\n",
    "    inx_mx_val=y_prob.iloc[i,inx_mx]\n",
    "    myfile.write(\"autogluon\"+\" \"+str(i)+\" \"+str(y_true[i])+\" \"+\"test\"+\" \"+str(inx_mx_val)+\" \"+str(inx_mx)+\"\\n\")\n",
    "y_pred = predictor.predict(val_df, model='NeuralNetTorch')\n",
    "y_prob = predictor.predict_proba(val_df)\n",
    "y_pred=[int(i) for i in list(y_pred)]\n",
    "y_true=[int(i) for i in list(val_df[\"label\"])]\n",
    "#report(y_true, y_pred,list(y_prob.iloc[:,1]), \"val\")\n",
    "for i in range(0,len(y_true)):\n",
    "    inx_mx=np.argmax(y_prob.iloc[i,:])\n",
    "    inx_mx_val=y_prob.iloc[i,inx_mx]\n",
    "    myfile.write(\"autogluon\"+\" \"+str(i)+\" \"+str(y_true[i])+\" \"+\"val\"+\" \"+str(inx_mx_val)+\" \"+str(inx_mx)+\"\\n\")\n",
    "y_pred = predictor.predict(train_df, model='NeuralNetTorch')\n",
    "y_prob = predictor.predict_proba(train_df)\n",
    "y_pred=[int(i) for i in list(y_pred)]\n",
    "y_true=[int(i) for i in list(train_df[\"label\"])]\n",
    "#report(y_true, y_pred,list(y_prob.iloc[:,1]), \"train\")\n",
    "for i in range(0,len(y_true)):\n",
    "    inx_mx=np.argmax(y_prob.iloc[i,:])\n",
    "    inx_mx_val=y_prob.iloc[i,inx_mx]\n",
    "    myfile.write(\"autogluon\"+\" \"+str(i)+\" \"+str(y_true[i])+\" \"+\"train\"+\" \"+str(inx_mx_val)+\" \"+str(inx_mx)+\"\\n\")\n",
    "myfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
